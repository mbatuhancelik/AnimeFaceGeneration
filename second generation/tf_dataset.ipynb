{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created and saves the dataset\n",
    "#Saves me from loading dataset from folder each training session(takes approximately 4 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.add_dll_directory(\"C:\\Program Files\\\\NVIDIA GPU Computing Toolkit\\CUDA\\\\v10.1\\\\bin\")\n",
    "os.add_dll_directory(\"C:\\Program Files\\\\NVIDIA GPU Computing Toolkit\\CUDA\\\\v10.1\\libnvvp\")\n",
    "os.add_dll_directory(\"C:\\Program Files\\\\NVIDIA GPU Computing Toolkit\\CUDA\\\\v10.1\")\n",
    "os.add_dll_directory(\"C:\\Program Files\\\\NVIDIA GPU Computing Toolkit\\CUDA\\\\v10.1\\extras\\CUPTI\\lib64\")\n",
    "os.add_dll_directory(\"C:\\Program Files\\\\NVIDIA GPU Computing Toolkit\\CUDA\\\\v10.1\\include\")\n",
    "os.add_dll_directory(\"C:\\Program Files\\\\NVIDIA Corporation\\\\Nsight Compute 2019.4.0\")\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, 'F:\\messy code\\\\afg ordered\\second generation')\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the paths of images that belong to games published after 2004\n",
    "def paths(img_dir):\n",
    "    img_paths = data.dir_to_list(img_dir)\n",
    "    result = []\n",
    "    dates = data.dates_directory(\"F:\\messy code\\\\afg ordered\\second generation\\image_collecting\\getchu\\data.txt\")\n",
    "    for path in img_paths: \n",
    "        name = data.path_to_name(path)\n",
    "        if int(dates[data.name_to_id(name)]) < 2005:\n",
    "            continue\n",
    "        result.append(path )\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = paths(\"F:\\messy code\\\\afg ordered\\second generation\\\\faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'F:\\\\messy code\\\\afg ordered\\\\second generation\\\\faces\\\\118x118_to_127x127\\\\725092char1_face0.jpg'>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = \"F:\\messy code\\\\afg ordered\\second generation\\getchu hopefully last\\content\\\\features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;dataset&#39; is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-10-7430fc0d4c11&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 20\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_to_picture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name &#39;dataset&#39; is not defined"
     ]
    }
   ],
   "source": [
    "def name_to_picture(path_tensor):\n",
    "    path = path_tensor.numpy().decode(\"utf-8\")\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "\n",
    "    name = data.path_to_name(path)\n",
    "    feature_path = data.name_to_feature_path(name , feature_dir)\n",
    "\n",
    "    feature_vector = np.load(feature_path)\n",
    "\n",
    "    feature_len = feature_vector.shape[0]\n",
    "\n",
    "    feature_vector = feature_vector.reshape(1, feature_len)\n",
    "    return tf.reshape(image, (1,128,128,3)) , feature_vector\n",
    "\n",
    "\n",
    "dataset = dataset.map(lambda x: tf.py_function(name_to_picture, [x], Tout = [tf.float32, tf.float32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Tensor: shape=(1, 128, 128, 3), dtype=float32, numpy=\n array([[[[1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          ...,\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ]],\n \n         [[1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          ...,\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ]],\n \n         [[1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          ...,\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ],\n          [1.        , 1.        , 1.        ]],\n \n         ...,\n \n         [[0.9750001 , 0.8443628 , 0.71004903],\n          [0.97613937, 0.84550214, 0.713467  ],\n          [0.9820677 , 0.8503486 , 0.7264917 ],\n          ...,\n          [0.98931724, 0.8561275 , 0.7143995 ],\n          [0.98823535, 0.8561275 , 0.72132355],\n          [0.98823535, 0.8561275 , 0.72132355]],\n \n         [[0.9803922 , 0.8470589 , 0.7012255 ],\n          [0.9860888 , 0.8527555 , 0.7135302 ],\n          [0.98998165, 0.8544846 , 0.725496  ],\n          ...,\n          [0.99178356, 0.8589098 , 0.72257394],\n          [0.98897064, 0.8595589 , 0.73014706],\n          [0.98897064, 0.8595589 , 0.73014706]],\n \n         [[0.9803922 , 0.8470589 , 0.69803923],\n          [0.99497557, 0.86164224, 0.7162684 ],\n          [0.99954045, 0.8696692 , 0.73149514],\n          ...,\n          [0.9921569 , 0.85928315, 0.7229473 ],\n          [0.9921569 , 0.86274517, 0.73333335],\n          [0.9921569 , 0.86274517, 0.73333335]]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 39), dtype=float32, numpy=\n array([[2.58881330e-01, 5.10042906e-03, 1.29371881e-03, 5.46991825e-04,\n         5.76406717e-04, 1.37132585e-01, 7.17208982e-02, 3.60754132e-03,\n         5.45650721e-04, 1.78480148e-03, 6.01679087e-04, 1.01178885e-04,\n         8.30963254e-03, 2.30564773e-02, 1.55925751e-04, 5.96463680e-04,\n         5.54263592e-04, 1.12903416e-02, 1.14375353e-03, 1.14142895e-05,\n         6.94066286e-04, 5.07831573e-05, 3.30191851e-03, 5.41415811e-03,\n         1.22803330e-01, 1.53043866e-03, 4.05544043e-03, 5.30153513e-03,\n         9.12100077e-04, 1.04516745e-04, 2.27744281e-02, 2.77048349e-03,\n         4.56184149e-03, 1.51118636e-03, 1.96364522e-03, 1.19137764e-03,\n         3.33402753e-02, 1.49072111e-02, 2.07536817e-02]], dtype=float32)>)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DatasetSpec((TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)), TensorShape([]))"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tf.data.DatasetSpec.from_value(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the dataset to be used on training\n",
    "tf.data.experimental.save(dataset ,'F:\\messy code\\\\afg ordered\\second generation\\\\tf_dataset_2' , compression = 'GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1102485char1_face0\n"
    }
   ],
   "source": [
    "save_pictures_dir = \"F:\\messy code\\\\afg ordered\\second generation\\\\faces_to_use_on_saving\"\n",
    "names = os.listdir(save_pictures_dir)\n",
    "print(names[0].split(\".\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset = tf.data.Dataset.from_tensor_slices(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_picture_save(path_tensor):\n",
    "    name = path_tensor.numpy().decode(\"utf-8\")\n",
    "    path = save_pictures_dir + \"\\\\\" + name\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    feature_path = data.name_to_feature_path( name.split(\".\")[0], feature_dir)\n",
    "    \n",
    "\n",
    "    feature_vector = np.load(feature_path)\n",
    "\n",
    "    feature_len = feature_vector.shape[0]\n",
    "\n",
    "    feature_vector = feature_vector.reshape(1, feature_len)\n",
    "\n",
    "    noise = noise = tf.random.uniform([5, 128])\n",
    "    return name ,tf.reshape(image, (1,128,128,3)) , feature_vector, noise\n",
    "\n",
    "\n",
    "save_dataset = save_dataset.map(lambda x: tf.py_function(name_to_picture_save, [x], Tout = [tf.string , tf.float32, tf.float32, tf.float32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DatasetSpec((TensorSpec(shape=&lt;unknown&gt;, dtype=tf.string, name=None), TensorSpec(shape=&lt;unknown&gt;, dtype=tf.float32, name=None), TensorSpec(shape=&lt;unknown&gt;, dtype=tf.float32, name=None), TensorSpec(shape=&lt;unknown&gt;, dtype=tf.float32, name=None)), TensorShape([]))"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "tf.data.DatasetSpec.from_value(save_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the dataet to be used on saving callback\n",
    "tf.data.experimental.save(save_dataset ,'F:\\messy code\\\\afg ordered\\second generation\\\\save_dataset' , compression = 'GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "91529a140531f0f278da87e0804b2d8f9218f9b902a86d69bc4fc0109344f3a8"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}